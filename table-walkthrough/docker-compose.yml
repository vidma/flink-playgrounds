################################################################################
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
# limitations under the License.
################################################################################

# see /docker-entrypoint.sh

version: '2.1'
services:
  client:
    build: .
    image: kensuio/kensu-flink-collector:cdh-table-walkthrough
    platform: linux/amd64
    # p.s. kensu collector jar is autodiscovered by flink from /opt/flink/lib/kensu-flink-collector.jar
    command: "/opt/flink/bin/flink run --detached /opt/flink/usrlib/spend-report.jar"
    #command: "sleep 1000"
    #entrypoint: "/bin/bash"
    depends_on:
      - jobmanager
      - kafka
    volumes:
      - ./conf:/opt/flink/conf
    environment:
      JOB_MANAGER_RPC_ADDRESS: "jobmanager"
      DAM_INGESTION_URL: "$KENSU_INGESTION_URL"
      AUTH_TOKEN: "${KENSU_AUTH_TOKEN}"
      STATS_COMPUTE_INTERVAL_MINUTES: "${STATS_COMPUTE_INTERVAL_MINUTES:-5}"
  jobmanager:
    image: kensuio/kensu-flink-collector:cdh-table-walkthrough
    platform: linux/amd64
    build: .
    hostname: "jobmanager"
    expose:
      - "6123"
      # fixme: second job for stats, hmm?
      # blob server ? fixme?
      - "6124"
    ports:
      - "8082:8081"
      - "6124:6124"
      - "6123:6123"
    # https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/resource-providers/standalone/overview/
    # or try https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/resource-providers/standalone/overview/#starting-a-standalone-cluster-session-mode
    command: "jobmanager"
    volumes:
      - ./conf:/opt/flink/conf
      - /tmp/flink-checkpoints-directory:/tmp/flink-checkpoints-directory
      - /tmp/flink-savepoints-directory:/tmp/flink-savepoints-directory
    environment:
      JOB_MANAGER_RPC_ADDRESS: "jobmanager"
      DAM_INGESTION_URL: "$KENSU_INGESTION_URL"
      AUTH_TOKEN: "${KENSU_AUTH_TOKEN}"
      STATS_COMPUTE_INTERVAL_MINUTES: "${STATS_COMPUTE_INTERVAL_MINUTES:-5}"
    depends_on:
      - kafka
      - mysql
  taskmanager:
    image: kensuio/kensu-flink-collector:cdh-table-walkthrough
    platform: linux/amd64
    build: .
    expose:
      - "6121"
      - "6122"
    depends_on:
      - jobmanager
    command: taskmanager
    # command: "taskmanager.sh start-foreground"
    links:
      - jobmanager:jobmanager
    volumes:
      - ./conf:/opt/flink/conf
      - /tmp/flink-checkpoints-directory:/tmp/flink-checkpoints-directory
      - /tmp/flink-savepoints-directory:/tmp/flink-savepoints-directory
    environment:
      JOB_MANAGER_RPC_ADDRESS: "jobmanager"
      DAM_INGESTION_URL: "$KENSU_INGESTION_URL"
      AUTH_TOKEN: "${KENSU_AUTH_TOKEN}"
  zookeeper:
    image: wurstmeister/zookeeper:3.4.6
    ports:
      - "2181:2181"
  kafka:
    image: wurstmeister/kafka:2.12-2.2.1
    ports:
      - "9092:9092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_ADVERTISED_HOST_NAME: "kafka"
      KAFKA_ADVERTISED_PORT: "9092"
      HOSTNAME_COMMAND: "route -n | awk '/UG[ \t]/{print $$2}'"
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CREATE_TOPICS: "kafka:1:1"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
  data-generator:
      image: kensuio/kensu-flink-collector:table-walkthrough-kafka-gen
      platform: linux/amd64
      build: ../docker/data-generator
      environment:
        KAFKA_TOPIC: "transactions"
      depends_on:
        - kafka
  data-generator-two:
    image: kensuio/kensu-flink-collector:table-walkthrough-kafka-gen
    platform: linux/amd64
    build: ../docker/data-generator
    environment:
      KAFKA_TOPIC: "aborted_transactions"
    depends_on:
      - kafka
  mysql:
    image: "${MYSQL_IMAGE:-mysql:8.0.19}"
    command: --default-authentication-plugin=mysql_native_password --secure_file_priv=/data
    environment:
      MYSQL_USER: "sql-demo"
      MYSQL_PASSWORD: "demo-sql"
      MYSQL_DATABASE: "sql-demo"
      MYSQL_RANDOM_ROOT_PASSWORD: "yes"
    volumes:
      - ../docker/mysql-spend-report-init:/docker-entrypoint-initdb.d
      - ./data:/data
  grafana:
    image: grafana/grafana:7.5.8
    ports:
      - "3000:3000"
    depends_on:
      - mysql
    volumes:
      - ../docker/grafana-spend-report-init/provisioning/:/etc/grafana/provisioning/
      - ../docker/grafana-spend-report-init/dashboard.json:/etc/grafana/dashboard.json
      - ../docker/grafana-spend-report-init/grafana.ini:/etc/grafana/grafana.ini
